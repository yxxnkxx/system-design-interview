# 4장 처리율 제한 장치의 설계

처리율 제한 장치(rate limiter): 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치

- HTTP: 특정 기간 내에 전송되는 클라이언트의 요청 횟수 제한
- API 요청 횟수가 임계치를 넘어서면 모든 호출 처리가 중단된다

### 처리율 제한 장치의 장점

- Dos(Denial of Service) 공격에 의한 자원 고갈 방지
- 비용 절감
- 서버 과부하 막음

## 문제 이해 및 설계 범위 확정

### 요구사항

- 설정된 처리율을 초과하는 요청은 정확하게 제한
- 낮은 응답시간
- 가능한 한 적은 메모리
- 분산형 처리율 제한(distributed rate limiting): 하나의 처리율 제한 장치를 여러 서버, 프로세스에서 공유
- 예외 처리: 요청이 제한되었다는 사실을 사용자에게 보여주어야 한다
- 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다

## 개략적 설계안 제시 및 동의 구하기

### 처리율 제한 장치는 어디에 둘 것인가?

- 클라이언트: 일반적으로 안정적인 장소x
- 서버

<img width="603" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/841b4d98-5fba-4f4a-83d4-bb8df8e7e814">

미들웨어로 API 서버로 가는 요청 통제

<img width="601" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/077b6262-9914-4092-a7e0-75e54a18ef35">

Http Status 429(Too Many Requests)를 반환

API 게이트웨이
- 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등
- 처리율 제한을 지원하는 미들웨어

지침

- 프로그래밍 언어, 캐시 서비스 등 현재 사용하고 있는 기술 스택 점검
- 사업 필요에 맞는 처리율 제한 알고리즘 찾기
- 직접 구현 < 상용 API 게이트웨이 사용 고려

### 처리율 제한 알고리즘

#### 토큰 버킷 알고리즘

- 토큰 버킷: 지정된 용량을 갖는 컨테이너
- 사전 설정된 양의 토큰이 주기적으로 생성
- 토큰이 꽉 찬 버킷에는 더 이상의 토큰이 추가되지 않는다
- 오버플로우된 토큰은 버려진다

각 요청은 처리될 때마다 하나의 토큰 사용
- 요청 -> 버킷에 충분한 토큰이 있는지 검사

<img width="634" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/430a0fde-b487-42f2-ac79-05da67730968">

- 토큰이 충분: 토큰을 하나 꺼낸 후 요청을 시스템에 전달
- 토큰이 부족: 해당 요청은 버려진다

2개의 파라미터
- 버킷 크기: 버킷에 담을 수 있는 최대 토큰 수
- 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가

사례
- 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다
- IP 주소별로 처리율 제한: IP 주소마다 버킷 할당
- 시스템의 처리율을 초당 n개의 요청으로 제한: 모든 요청이 하나의 버킷 공유

**장점**
- 구현이 쉬움
- 메모리 사용 효율적
- 짧은 시간에 집중되는 트래픽 처리 가능

**단점**
- 버킷 크기, 토큰 공급률을 튜닝하는 것이 까다로움

#### 누출 버킷 알고리즘

토큰 버킷 알고리즘과 비슷 + 요청 처리율 고정

FIFO 큐로 구현

- 요청이 도착하면 큐가 가득 차 있는지 확인
- 큐가 가득 차 있는 경우 새 요청은 버린다
- 지정된 시간마다 큐에서 요청을 꺼내어 처리

<img width="644" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/7bfbb2f7-f8d3-4674-a62d-8a18899d9c2d">

2개의 파라미터
- 버킷 크기: 큐 사이즈
- 처리율: 지정된 시간당 몇 개의 항목을 처리할지 (보통 초 단위로 표현)

**장점**
- 큐의 크기 제한, 메모리 사용 효율
- 고정된 처리율: 안정적 출력이 필요한 경우에 적합

**단점**
- 단시간에 많은 트래픽이 몰리는 경우: 큐에 오래된 요청들이 쌓이고, 최신 요청들이 버려진다
- 두 개 인자 튜닝하는 것이 까다로움

#### 고정 윈도우 카운터 알고리즘

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도우마다 카운터를 붙인다
- 요청이 접수될 때마다 카운터 값이 1씩 증가
- 카운터 값이 임계치에 도달: 새로운 요청은 새 윈도우가 열릴 때까지 버려진다

**장점**
- 메모리 효율이 좋다
- 이해하기 쉽다
- 윈도우가 닫히는 시점에 카운터 초기화: 특정 트래픽 패턴을 처리하기에 적합

**단점**
- 윈도우의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도우에 할당된 양보다 더 많은 요청이 처리될 수 있다

#### 슬라이딩 윈도우 로깅 알고리즘

- 요청의 타임스탬프 추적: 타임스탬프 데이터는 보통 redis의 sorted set 같은 캐시에 저장
- 새 요청이 오면 만료된 타임스탬프 제거 (만료=현재 윈도우의 시작 지점보다 오래된 타임스탬프)
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기에 따라 요청 전달/거부
  - 허용 한도보다 로그의 크기가 작은 경우: 요청 전달
  - 허용 한도보다 로그의 크기가 큰 경우: 로그에 남아있고, 요청은 거부

<img width="510" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/2fc81c16-8d14-42e6-8238-74fd55e9400b">

**장점**
- 어느 순간의 윈도우를 보더라도 윈도우 내의 요청 수가 허용 한도를 넘지 않는다

**단점**
- 다량의 메모리 사용: 거부된 요청의 타임스탬프 보관

#### 슬라이딩 윈도우 카운터 알고리즘

고정 윈도우 카운터 알고리즘 + 슬라이딩 윈도우 로깅 알고리즘

<img width="645" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/f1caf661-106b-4296-9478-462e8e5f4926">

ex) 분당 7개 요청으로 제한

계산 방식: 현재 1분간의 요청 수 + 직전 1분간의 요청수 * 슬라이딩 윈도우와 직전 1분이 겹치는 비율

**장점**
- 이전 시간대의 평균 처리율에 따라 현재 윈도우의 상태를 계산: 짧은 시간에 몰리는 트래픽에도 잘 대응
- 메모리 효율이 좋음

**단점**
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정: 느슨한 계산
    - Cloudflare: 실제 상태와 맞지 않게 처리된 요청: 0.003%

### 개략적인 아키텍처
<img width="646" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/c7ac30b1-4ff0-4985-815c-3a533fb5b867">

- 클라이언트가 처리율 제한 미들웨어에 요청을 보냄
- 미들웨어: 레디스의 지정 버킷에서 카운터를 가져와 검사

## 상세 설계

### 처리율 제한 규칙

```
domain: messaging
descriptors:
    - key: message_type
      Value: marketing
      rate_limit:
        unit: day
        requests_per_unit: 5
```
하루에 처리할 수 있는 마케팅 메시지의 최대치를 5개로 제한
config 파일 형태로 디스크에 저장

### 처리율 한도 초과 트래픽의 처리
한도 제한 -> API는 HTTP 429 dmdekqdmf qksghks
- 한도 제한에 걸린 메시지를 나중에 처리하기 위해 큐에 보관도 가능

#### 처리율 제한 장치가 사용하는 HTTP 헤더
- X-RateLimit-Remaining: 윈도우 내에 남은 처리 가능 요청의 수
- X-RateLimit-Limit: 매 윈도우 마다 처리 가능한 요청의 수
- X-RateLimit-Retry-After: 다음 요청을 보낼 수 있는 시간

### 상세 설계

<img width="683" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/1bea93c6-1540-4867-acf7-05d04083ea06">

- 처리율 제한 규칙: 디스크에 보관
- 작업 프로세스: 규치긍ㄹ 디스크에서 읽어 캐시에 저장
- 클라이언트가 요청을 보내면 처리율 제한 미들웨어에 도달
- 처리율 제한 미들웨어
  - 제한 규칙을 캐시에서 가져온다
  - 카운터/마지막 요청의 타임스탬프를 레디스 캐시에서 가져옴

### 분산 환경에서의 처리율 제한 장치의 구현

#### 경쟁 조건 (race condition)

동시에 카운터 접근 시 처리율 제한 초과

해결책
- 락
- lua script https://stripe.com/blog/rate-limiters
- redis sorted set https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/

#### 동기화 이슈

처리율 제한 장치 서버를 여러 대 둘 경우 동기화 필요

해결책
- 고정 세션: 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치
  - 확장 가능하지 않음
- 레디스: 중앙 집중형 데이터 저장소 사용

<img width="603" alt="image" src="https://github.com/yxxnkxx/system-design-interview/assets/109255398/778969be-a7c3-4928-bfe3-808b079996e4">

#### 성능 최적화

- 여러 데이터 센터 지원: 지연 시간 감소(edge server 필요)
- 최종 일관성 모델 사용

#### 모니터링

- 채택된 처리율 제한 알고리즘이 효과적
- 정의한 처리율 제한 규칙이 효과적

## 마무리
- 경성/연성 처리율 제한
  - 경성 처리율 제한: 요청 개수는 임계치를 절대 넘어설 수는 없다
  - 연성 처리율 제한: 요청 개수는 잠시 동안은 임계치를 넘어설 수 있다
- 다양한 계층에서의 처리율 제한
- 처리율 제한 회피 방법
  - 클라이언트 측 캐시 사용: API 호출 횟수를 줄인다
  - 처리율 제한의 임계치를 이해
  - 예외나 에러를 처리하는 코드를 도입: 클라이언트가 gracefully 복구될 수 있도록 한다
  - 재시도 로직: 충분한 백오프 시간